{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c9ac8f",
   "metadata": {},
   "source": [
    "# Download Dataset\n",
    "OntoNotes-5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4976aa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nltk) (4.61.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from click->nltk) (4.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.10.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.4.1)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.6.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d7d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1702c72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'OntoNotes-5.0-NER-BIO'...\n",
      "remote: Enumerating objects: 27517, done.\u001b[K\n",
      "remote: Total 27517 (delta 0), reused 0 (delta 0), pack-reused 27517\u001b[K\n",
      "\u001b[KReceiving objects: 100% (27517/27517), 101.80 MiB | 7.37 MiB/s, done.\n",
      "\u001b[KResolving deltas: 100% (19834/19834), done.\n",
      "\u001b[KUpdating files: 100% (26670/26670), done. files:  20% (5334/26670)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/yuchenlin/OntoNotes-5.0-NER-BIO.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbb41ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gn_glove'...\n",
      "remote: Enumerating objects: 199, done.\u001b[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 199 (delta 2), reused 0 (delta 0), pack-reused 193\u001b[K\n",
      "\u001b[KReceiving objects: 100% (199/199), 67.78 KiB | 1.17 MiB/s, done.\n",
      "\u001b[KResolving deltas: 100% (88/88), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/uclanlp/gn_glove.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3570cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!for path in $(find ./OntoNotes-5.0-NER-BIO/conll-formatted-ontonotes-5.0/data/ -name \"*.gold_conll\"); do sed 's/  */,/g; s/\"/\"\"/g' ${path} > ${path}.csv;done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2c5d7",
   "metadata": {},
   "source": [
    "# Load pre_trained model: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc69a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (20.9)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting requests\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 7.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-macosx_10_11_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-macosx_10_9_x86_64.whl (249 kB)\n",
      "\u001b[K     |████████████████████████████████| 249 kB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (4.61.0)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from transformers) (4.5.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2021.4.4-cp37-cp37m-macosx_10_9_x86_64.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from huggingface-hub==0.0.12->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Installing collected packages: urllib3, idna, chardet, certifi, requests, regex, filelock, tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
      "Successfully installed certifi-2021.5.30 chardet-4.0.0 filelock-3.0.12 huggingface-hub-0.0.12 idna-2.10 pyyaml-5.4.1 regex-2021.4.4 requests-2.25.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.1 urllib3-1.26.6\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dad5559",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-17a774fd22dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde481ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecc8b6d3821474ebd8b09e38bb3b909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040c0b3523564eedaa4d73b66fa1fe3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9a37587d0c444184ea572cb930cdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0343ed938d14d97a11e116de7251ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224037df1b594d0389a0c2970937bd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# For DistilBERT:a version of BERT that is smaller, but much faster and requiring a lot less memory.\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1e6c4",
   "metadata": {},
   "source": [
    "# Quantify bias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4fe38d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9840681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'allennlp'...\n",
      "remote: Enumerating objects: 37918, done.\u001b[K\n",
      "remote: Counting objects: 100% (744/744), done.\u001b[K\n",
      "remote: Compressing objects: 100% (365/365), done.\u001b[K\n",
      "^CKReceiving objects:  98% (37173/37918), 56.37 MiB | 3.72 MiB/sReceiving objects:  71% (27039/37918), 30.51 MiB | 3.27 MiB/s\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/allenai/allennlp.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28377e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits(sentence: str) -> np.ndarray:\n",
    "    return model(processor.to_bert_model_input(sentence))[0, :, :].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510b55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(arr, axis=1):\n",
    "    e = np.exp(arr)\n",
    "    return e / e.sum(axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9027775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_fill_logits(sentence, words: Iterable[str],\n",
    "                         use_last_mask=False, apply_softmax=False) -> Dict[str, float]:\n",
    "    mask_i = processor.get_index(sentence, \"[MASK]\", last=use_last_mask)\n",
    "    logits = defaultdict(list)\n",
    "    out_logits = get_logits(sentence)\n",
    "    if apply_softmax: \n",
    "        out_logits = softmax(out_logits)\n",
    "    return {w: out_logits[mask_i, processor.token_to_index(w)] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac397d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he she\n"
     ]
    }
   ],
   "source": [
    "gender_words=['he','she']\n",
    "mw, fw = gender_words\n",
    "print(mw,fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a553abb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Iterable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-855a17a838c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m def bias_score(sentence: str, gender_words: Iterable[str], \n\u001b[0;32m----> 2\u001b[0;31m                word: str, gender_comes_first=True) -> Dict[str, float]:\n\u001b[0m\u001b[1;32m      3\u001b[0m     \"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0mInput\u001b[0m \u001b[0ma\u001b[0m \u001b[0msentence\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mform\u001b[0m \u001b[0;34m\"GGG is XXX\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mXXX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mplaceholder\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Iterable' is not defined"
     ]
    }
   ],
   "source": [
    "def bias_score(sentence, gender_words, target_words):# should be str \n",
    "    \"\"\"\n",
    "    Input a sentence of the form \"GGG is XXX\"\n",
    "    XXX is a placeholder for the target word\n",
    "    GGG is a placeholder for the gendered words (the subject)\n",
    "    We will predict the bias when filling in the gendered words and \n",
    "    filling in the target word.\n",
    "    \"\"\"\n",
    "    # probability of filling [MASK] with \"he\" vs. \"she\" when target is \"programmer\"\n",
    "    mwords, fwords = gender_words\n",
    "    subject_fill_logits = get_mask_fill_logits(\n",
    "        sentence.replace(\"XXX\", i for i in target_words).replace(\"GGG\", \"[MASK]\"), # the sentence replaced by [mask]\n",
    "        gender_words, use_last_mask=not gender_comes_first,\n",
    "    )\n",
    "    subject_fill_bias = subject_fill_logits[mwords] - subject_fill_logits[fwords]\n",
    "    # male words are simply more likely than female words\n",
    "    # correct for this by masking the target word and measuring the prior probabilities\n",
    "    subject_fill_prior_logits = get_mask_fill_logits(\n",
    "        sentence.replace(\"XXX\", \"[MASK]\").replace(\"GGG\", \"[MASK]\"), \n",
    "        gender_words, #use_last_mask=gender_comes_first,\n",
    "    )\n",
    "    subject_fill_bias_prior_correction = subject_fill_prior_logits[mw] -                                             subject_fill_prior_logits[fw]\n",
    "    \n",
    "    # probability of filling \"programmer\" into [MASK] when subject is male/female\n",
    "    try:\n",
    "        mw_fill_prob = get_mask_fill_logits(\n",
    "            sentence.replace(\"GGG\", mw).replace(\"XXX\", \"[MASK]\"), [word],\n",
    "            apply_softmax=True,\n",
    "        )[word]\n",
    "        fw_fill_prob = get_mask_fill_logits(\n",
    "            sentence.replace(\"GGG\", fw).replace(\"XXX\", \"[MASK]\"), [word],\n",
    "            apply_softmax=True,\n",
    "        )[word]\n",
    "        # We don't need to correct for the prior probability here since the probability\n",
    "        # should already be conditioned on the presence of the word in question\n",
    "        tgt_fill_bias = np.log(mw_fill_prob / fw_fill_prob)\n",
    "    except:\n",
    "        tgt_fill_bias = np.nan # TODO: handle multi word case\n",
    "    return {\"gender_fill_bias\": subject_fill_bias,\n",
    "            \"gender_fill_prior_correction\": subject_fill_bias_prior_correction,\n",
    "            \"gender_fill_bias_prior_corrected\": subject_fill_bias - subject_fill_bias_prior_correction,\n",
    "            \"target_fill_bias\": tgt_fill_bias, \n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad3515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
